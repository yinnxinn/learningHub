---
title: "The Illustrated Transformer"
description: "Jay Alammar 通过图解方式拆解 Transformer 架构，适合快速理解注意力机制。"
url: "https://jalammar.github.io/illustrated-transformer/"
tags: ["大模型", "Transformer", "可视化讲解"]
contributor: "@learning-share"
recommendation: 5
---

## 推荐理由
- 采用动画与高亮示意，清晰展示 Self-Attention 的计算流程。
- 对 Encoder-Decoder 结构、残差连接、位置编码等概念逐一拆解。
- 文章末尾提供多篇延伸阅读，帮助深入原始论文与实现。

## 学习建议
1. 在阅读时同步对照原论文《Attention Is All You Need》，理解公式与示意图之间的映射。
2. 结合代码实现（如 `transformers` 或 `tensor2tensor`）查看多头注意力的具体实现。
3. 将文章中的关键图示保存到笔记中，作为面试或讲解时的素材。
